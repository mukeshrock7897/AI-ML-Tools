{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸâš¡ LangServe â€” Ultimate Cheatsheet\n",
    "\n",
    "> **Mental model:** LangServe turns **LCEL/LangGraph runnables** into **typed HTTP APIs** (FastAPI) with **/invoke â€¢ /batch â€¢ /stream**, **Pydantic I/O**, **SSE streaming**, **RemoteRunnable clients**, plus hooks for **auth ğŸ”**, **observability ğŸ‘€**, **caching ğŸ’¾**, and **scaling ğŸ“ˆ**.\n",
    "\n",
    "---\n",
    "\n",
    "## 0) ğŸ§­ Core Concepts (Orientation)\n",
    "\n",
    "| ğŸ”§ Concept   | ğŸ“ What it means                                             | ğŸ¯ Why it matters             |\n",
    "| ------------ | ------------------------------------------------------------ | ----------------------------- |\n",
    "| **Runnable** | Your chain/agent/graph implementing `.invoke/.batch/.stream` | One uniform server contract   |\n",
    "| **Route**    | `add_routes(app, runnable, path=\"/...\")`                     | Zero-boilerplate API surface  |\n",
    "| **Client**   | Python/JS/HTTP caller                                        | Local â†” remote symmetry       |\n",
    "| **Modes**    | `invoke` (one) â€¢ `batch` (many) â€¢ `stream` (tokens)          | Balance latency vs throughput |\n",
    "| **Schemas**  | Pydantic request/response models                             | Strong contracts & OpenAPI âœ…  |\n",
    "\n",
    "**Interview one-liner:** *â€œLangServe is the thinnest way to put LCEL/LangGraph behind typed, streaming endpoints with observability and auth.â€* âœ¨\n",
    "\n",
    "---\n",
    "\n",
    "## 1) ğŸ› ï¸ Install & Project Scaffold\n",
    "\n",
    "| ğŸ§© Task  | ğŸ’» Command / Tip                                      | ğŸ—’ï¸ Notes             |\n",
    "| -------- | ----------------------------------------------------- | --------------------- |\n",
    "| Install  | `pip install langserve fastapi uvicorn pydantic`      | Pin versions for prod |\n",
    "| Scaffold | `app.py` + `runnables.py` + `settings.py`             | Keep routes modular   |\n",
    "| Run      | `uvicorn app:app --host 0.0.0.0 --port 8000 --reload` | `--reload` for dev ğŸ” |\n",
    "\n",
    "---\n",
    "\n",
    "## 2) ğŸš§ Build Your First Service\n",
    "\n",
    "### 2.1 ğŸ§¾ IO Schemas (Pydantic)\n",
    "\n",
    "```python\n",
    "# schemas.py\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ChatIn(BaseModel):\n",
    "    question: str = Field(..., min_length=1)\n",
    "\n",
    "class ChatOut(BaseModel):\n",
    "    answer: str\n",
    "```\n",
    "\n",
    "### 2.2 ğŸ”Œ Wrap a Runnable with `add_routes`\n",
    "\n",
    "```python\n",
    "# app.py\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from schemas import ChatIn, ChatOut\n",
    "\n",
    "app = FastAPI(title=\"LangServe Demo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer concisely:\\nQ: {question}\\nA:\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = prompt | llm  # Runnable\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/chat\",\n",
    "    input_schema=ChatIn,      # optional: inferred if omitted\n",
    "    output_schema=ChatOut     # optional: use parser for strict JSON\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) ğŸ›£ï¸ Routes & Endpoints\n",
    "\n",
    "| ğŸ”— Endpoint    | ğŸ§­ Method  | ğŸ“¦ Body (typical)                                     | ğŸ Returns                 |\n",
    "| -------------- | ---------- | ----------------------------------------------------- | -------------------------- |\n",
    "| `/chat/invoke` | POST       | `{\"input\":{\"question\":\"...\"}, \"config\": {...}}`       | Single result              |\n",
    "| `/chat/batch`  | POST       | `{\"inputs\":[{\"question\":\"...\"}...], \"config\": {...}}` | List of results            |\n",
    "| `/chat/stream` | POST (SSE) | Same as `/invoke`                                     | `text/event-stream` tokens |\n",
    "| Options & CORS | â€”          | Tags/description/CORS allowlist                       | OpenAPI auto-updates ğŸ“œ    |\n",
    "\n",
    "> ğŸ’¡ **Pro tip:** `config` supports `tags`, `metadata`, and `configurable` (e.g. `{\"session_id\":\"abc\"}`) that flow into LCEL/LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) ğŸ“¡ Streaming (Server & Clients)\n",
    "\n",
    "### 4.1 ğŸ§¨ SSE from `/stream`\n",
    "\n",
    "* Content-Type: `text/event-stream`\n",
    "* Emits tokens + final message â†’ perfect for chat UIs ğŸ’¬\n",
    "\n",
    "### 4.2 ğŸ Python client streaming\n",
    "\n",
    "```python\n",
    "from langserve import RemoteRunnable\n",
    "rr = RemoteRunnable(\"http://localhost:8000/chat/\")\n",
    "for chunk in rr.stream({\"question\": \"Hello?\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "```\n",
    "\n",
    "### 4.3 ğŸŒ Browser (JS) streaming\n",
    "\n",
    "```js\n",
    "const resp = await fetch(\"http://localhost:8000/chat/stream\", {\n",
    "  method: \"POST\",\n",
    "  headers: { \"Content-Type\": \"application/json\" },\n",
    "  body: JSON.stringify({ input: { question: \"Hi?\" } }),\n",
    "});\n",
    "const reader = resp.body.getReader();\n",
    "const decoder = new TextDecoder();\n",
    "while (true) {\n",
    "  const { value, done } = await reader.read();\n",
    "  if (done) break;\n",
    "  console.log(decoder.decode(value)); // parse SSE frames\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5) ğŸ¤ Clients & RemoteRunnable\n",
    "\n",
    "| ğŸ§° Client      | ğŸƒ How to call                                 | ğŸ—’ï¸ Notes                  |\n",
    "| -------------- | ---------------------------------------------- | -------------------------- |\n",
    "| **Python**     | `RemoteRunnable(url).invoke/stream/batch(...)` | Mirrors local Runnable API |\n",
    "| **JavaScript** | `fetch` or generated SDK from OpenAPI          | Prefer SSE for `/stream`   |\n",
    "| **OpenAPI**    | `GET /openapi.json`                            | Generate TS/Java SDKs ğŸ§ª   |\n",
    "\n",
    "---\n",
    "\n",
    "## 6) ğŸ” Auth & Security\n",
    "\n",
    "| ğŸš§ Concern    | ğŸ§­ Pattern                                          | ğŸ” Snippet          |\n",
    "| ------------- | --------------------------------------------------- | ------------------- |\n",
    "| API key       | FastAPI dependency, read header (e.g., `x-api-key`) | See below           |\n",
    "| CORS          | Allow specific origins                              | Add CORS middleware |\n",
    "| Rate limiting | NGINX/Cloud or middleware                           | Per-IP / per-key    |\n",
    "| Secrets       | Env/vault; never log                                | Pydantic Settings   |\n",
    "\n",
    "**ğŸ”‘ API-Key example**\n",
    "\n",
    "```python\n",
    "from fastapi import Depends, HTTPException, Header\n",
    "def require_key(x_api_key: str | None = Header(default=None)):\n",
    "    if x_api_key != \"supersecret\":\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n",
    "add_routes(app, chain, path=\"/chat\", dependencies=[Depends(require_key)])\n",
    "```\n",
    "\n",
    "**ğŸŒ CORS**\n",
    "\n",
    "```python\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7) ğŸ‘€ Observability (LangSmith & OTel)\n",
    "\n",
    "| ğŸ“Œ Area           | ğŸ› ï¸ How                                   | ğŸ’¡ Tip                          |\n",
    "| ----------------- | ----------------------------------------- | ------------------------------- |\n",
    "| LangSmith tracing | `LANGSMITH_API_KEY` + tags/metadata       | tag `env`, `release`, `feature` |\n",
    "| Logs & metrics    | OpenTelemetry for FastAPI/uvicorn         | Merge with infra dashboards     |\n",
    "| Per-route KPIs    | Tag by route/node; watch p50/p95 & tokens | Drive SLOs by path âœ…            |\n",
    "\n",
    "---\n",
    "\n",
    "## 8) ğŸ§ª Testing\n",
    "\n",
    "| ğŸ§ª Type         | ğŸ”§ How                                    | ğŸ—’ï¸ Notes                      |\n",
    "| --------------- | ----------------------------------------- | ------------------------------ |\n",
    "| OpenAPI & SDK   | Validate `/openapi.json`; generate TS SDK | Contract tests at boundary     |\n",
    "| Unit & contract | `pytest` + `TestClient(app)`              | Golden outputs & schema checks |\n",
    "| Load tests      | k6/Locust/Gatling vs `/batch` & `/stream` | Watch p95, CPU, memory         |\n",
    "\n",
    "**Contract test**\n",
    "\n",
    "```python\n",
    "from fastapi.testclient import TestClient\n",
    "from app import app\n",
    "\n",
    "def test_invoke_contract():\n",
    "    c = TestClient(app)\n",
    "    r = c.post(\"/chat/invoke\", json={\"input\":{\"question\":\"ping\"}})\n",
    "    assert r.status_code == 200\n",
    "    body = r.json()\n",
    "    assert \"output\" in body and \"answer\" in body[\"output\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9) ğŸš€ Performance & Scaling\n",
    "\n",
    "| âš™ï¸ Lever         | ğŸ§­ What to do                                  | ğŸ“ Notes                    |\n",
    "| ---------------- | ---------------------------------------------- | --------------------------- |\n",
    "| Async everywhere | Non-blocking I/O in nodes                      | Offload blocking ops        |\n",
    "| Concurrency      | Uvicorn/Gunicorn workers, thread/process pools | Size by CPU & model latency |\n",
    "| Backpressure     | Queue & drop policies                          | Protect upstream LLMs       |\n",
    "| Timeouts         | Client & server per-route                      | Avoid resource leaks        |\n",
    "| Load balancing   | NGINX/LB, sticky if in-mem state               | Health probes on `/docs` â¤ï¸ |\n",
    "\n",
    "---\n",
    "\n",
    "## 10) ğŸ§  Caching & State\n",
    "\n",
    "| ğŸ§© Topic             | ğŸ”§ How                               | ğŸ—’ï¸ Notes                |\n",
    "| -------------------- | ------------------------------------ | ------------------------ |\n",
    "| LLM cache            | LangChain Cache (in-mem/Redis)       | Cache by prompt+params   |\n",
    "| Tool/retriever cache | Memoize deterministic calls          | TTL & invalidation hooks |\n",
    "| Session memory       | Pass `session_id` via `configurable` | Per-user chat state      |\n",
    "| Idempotency          | Request IDs for dedup                | Record in traces         |\n",
    "\n",
    "**Session config (client)**\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"session_id\": \"user-123\"}}\n",
    "RemoteRunnable(\"http://.../chat/\").invoke({\"question\": \"...\"}, config=config)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 11) ğŸ›¡ï¸ Error Handling & Reliability\n",
    "\n",
    "| ğŸš¨ Concern           | ğŸ§­ Pattern                                                | ğŸ’¡ Tip                   |\n",
    "| -------------------- | --------------------------------------------------------- | ------------------------ |\n",
    "| Exceptions â†’ 4xx/5xx | Raise `HTTPException`; map known errors                   | Clear error contracts    |\n",
    "| Retries & backoff    | Client retries idempotent calls; server wraps fragile I/O | Tag retry reason         |\n",
    "| Validation errors    | Pydantic â†’ HTTP 422                                       | Keep schemas strict      |\n",
    "| Circuit breakers     | Fail fast on dependency errors                            | Consider `Retry-After` â³ |\n",
    "\n",
    "---\n",
    "\n",
    "## 12) ğŸŒ Deployment\n",
    "\n",
    "| â˜ï¸ Target            | ğŸ”§ How                                      | ğŸ—’ï¸ Notes           |\n",
    "| -------------------- | ------------------------------------------- | ------------------- |\n",
    "| Containers           | Multi-stage Dockerfile, slim base, non-root | Healthcheck `/docs` |\n",
    "| Cloud run/serverless | Container; set concurrency/timeouts         | Mind cold starts â„ï¸ |\n",
    "| Reverse proxy & TLS  | NGINX/Traefik + SSL termination             | gzip/br compression |\n",
    "| Env config           | Pydantic Settings + `.env`/vault            | Immutable on boot   |\n",
    "\n",
    "---\n",
    "\n",
    "## 13) ğŸ§© Advanced\n",
    "\n",
    "| ğŸª„ Topic               | ğŸ”§ How                                     | ğŸ—’ï¸ Notes                |\n",
    "| ---------------------- | ------------------------------------------ | ------------------------ |\n",
    "| Multimodal I/O         | Pydantic `bytes`/base64/URL fields         | Validate size & MIME     |\n",
    "| Serve LangGraph agents | Wrap `graph_app` via `add_routes`          | Expose `invoke/stream`   |\n",
    "| Tools & files          | `multipart/form-data` â†’ parse to tool args | Handle temp files safely |\n",
    "\n",
    "**Multipart upload (concept)**\n",
    "\n",
    "```python\n",
    "from fastapi import File, UploadFile\n",
    "\n",
    "@app.post(\"/ingest\")\n",
    "async def ingest(file: UploadFile = File(...)):\n",
    "    data = await file.read()\n",
    "    return {\"ok\": True, \"bytes\": len(data)}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14) ğŸ–¥ï¸ Frontend Integration\n",
    "\n",
    "| ğŸ¯ Need        | ğŸ§­ Pattern           | ğŸ’¡ Tip                           |\n",
    "| -------------- | -------------------- | -------------------------------- |\n",
    "| Minimal web UI | `fetch` `/invoke`    | Debounce inputs                  |\n",
    "| Live tokens    | `/stream` (SSE)      | `EventSource` / `ReadableStream` |\n",
    "| CORS           | Allow your FE origin | Lock down in prod ğŸ”’             |\n",
    "\n",
    "**Browser fetch**\n",
    "\n",
    "```js\n",
    "const r = await fetch(\"/chat/invoke\", {\n",
    "  method: \"POST\",\n",
    "  headers: { \"Content-Type\": \"application/json\", \"x-api-key\": \"supersecret\" },\n",
    "  body: JSON.stringify({ input: { question: \"Hello\" } }),\n",
    "});\n",
    "const { output } = await r.json();\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15) âš¡ â€œAnswer-in-a-Minuteâ€ Boilerplates\n",
    "\n",
    "**A) Minimal app**\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "app = FastAPI()\n",
    "chain = PromptTemplate.from_template(\"Q:{q}\\nA:\") | ChatOpenAI(temperature=0)\n",
    "add_routes(app, chain, path=\"/qa\")\n",
    "```\n",
    "\n",
    "**B) Protected streaming route**\n",
    "\n",
    "```python\n",
    "from fastapi import Depends, Header, HTTPException\n",
    "def require_key(x_api_key: str | None = Header(default=None)):\n",
    "    if x_api_key != \"k\": raise HTTPException(401, \"bad key\")\n",
    "add_routes(app, chain, path=\"/qa\", dependencies=[Depends(require_key)])\n",
    "# POST /qa/stream with {\"input\":{\"q\":\"...\"}}\n",
    "```\n",
    "\n",
    "**C) Remote client (Python)**\n",
    "\n",
    "```python\n",
    "from langserve import RemoteRunnable\n",
    "rr = RemoteRunnable(\"https://api.example.com/qa/\")\n",
    "ans = rr.invoke({\"q\": \"What is LangServe?\"})\n",
    "```\n",
    "\n",
    "**D) OpenAPI â†’ SDK (concept)**\n",
    "\n",
    "* Download `/openapi.json` â†’ generate TypeScript SDK â†’ call `invoke/batch/stream`.\n",
    "\n",
    "---\n",
    "\n",
    "## 16) âœ… Checklists\n",
    "\n",
    "**Production Readiness**\n",
    "\n",
    "* ğŸ”’ Auth (key) â€¢ ğŸŒ CORS allowlist â€¢ â±ï¸ Timeouts â€¢ ğŸ§¯ Retries/backoff\n",
    "* ğŸ“ˆ Tracing/metrics on â€¢ ğŸ’¾ Cache strategy â€¢ ğŸ§µ Concurrency sized\n",
    "* ğŸš¦ Health probes â€¢ ğŸ§ª Contract tests â€¢ ğŸ” Rollback plan\n",
    "\n",
    "**Performance**\n",
    "\n",
    "* âš¡ Async everywhere â€¢ ğŸ§° Worker counts tuned â€¢ ğŸ§± Backpressure at ingress\n",
    "* ğŸ§® Batch where possible â€¢ ğŸ§Š Cache hot prompts â€¢ ğŸ“Š p95 & cost dashboards\n",
    "\n",
    "**Safety**\n",
    "\n",
    "* ğŸ§° Strict schemas â€¢ ğŸ“œ Error contracts â€¢ ğŸ•µï¸ PII redaction â€¢ ğŸ” Secret hygiene\n",
    "\n",
    "---\n",
    "\n",
    "## 17) ğŸš« Common Pitfalls â†’ âœ… Fix\n",
    "\n",
    "| âš ï¸ Pitfall                    | âœ… Fix                                  |\n",
    "| ----------------------------- | -------------------------------------- |\n",
    "| Free-shape JSON inputs        | Always use Pydantic schemas            |\n",
    "| Blocking calls in async nodes | Offload to thread/process pool         |\n",
    "| No streaming for chat         | Use `/stream` SSE â†’ better TTFB/UX     |\n",
    "| CORS failures in browser      | Configure `allow_origins` correctly    |\n",
    "| Secret leakage in logs        | Redact + disable debug logs in prod    |\n",
    "| Unbounded concurrency         | Set worker limits + queue/backpressure |\n",
    "\n",
    "---\n",
    "\n",
    "## 18) ğŸ¤ Quick Talking Points\n",
    "\n",
    "* *â€œAny Runnable becomes `/invoke`, `/batch`, `/stream` with strict Pydantic I/O.â€*\n",
    "* *â€œ**RemoteRunnable** mirrors local APIsâ€”switch local â†” remote with a URL.â€*\n",
    "* *â€œAuth + schemas + rate limits at the edge; SSE streaming for buttery UX.â€*\n",
    "* *â€œLangSmith/OTel tracing + caching + contract tests = safe, scalable prod.â€*\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
