{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🏁⚡ LangServe — Ultimate Cheatsheet\n",
    "\n",
    "> **Mental model:** LangServe turns **LCEL/LangGraph runnables** into **typed HTTP APIs** (FastAPI) with **/invoke • /batch • /stream**, **Pydantic I/O**, **SSE streaming**, **RemoteRunnable clients**, plus hooks for **auth 🔐**, **observability 👀**, **caching 💾**, and **scaling 📈**.\n",
    "\n",
    "---\n",
    "\n",
    "## 0) 🧭 Core Concepts (Orientation)\n",
    "\n",
    "| 🔧 Concept   | 📝 What it means                                             | 🎯 Why it matters             |\n",
    "| ------------ | ------------------------------------------------------------ | ----------------------------- |\n",
    "| **Runnable** | Your chain/agent/graph implementing `.invoke/.batch/.stream` | One uniform server contract   |\n",
    "| **Route**    | `add_routes(app, runnable, path=\"/...\")`                     | Zero-boilerplate API surface  |\n",
    "| **Client**   | Python/JS/HTTP caller                                        | Local ↔ remote symmetry       |\n",
    "| **Modes**    | `invoke` (one) • `batch` (many) • `stream` (tokens)          | Balance latency vs throughput |\n",
    "| **Schemas**  | Pydantic request/response models                             | Strong contracts & OpenAPI ✅  |\n",
    "\n",
    "**Interview one-liner:** *“LangServe is the thinnest way to put LCEL/LangGraph behind typed, streaming endpoints with observability and auth.”* ✨\n",
    "\n",
    "---\n",
    "\n",
    "## 1) 🛠️ Install & Project Scaffold\n",
    "\n",
    "| 🧩 Task  | 💻 Command / Tip                                      | 🗒️ Notes             |\n",
    "| -------- | ----------------------------------------------------- | --------------------- |\n",
    "| Install  | `pip install langserve fastapi uvicorn pydantic`      | Pin versions for prod |\n",
    "| Scaffold | `app.py` + `runnables.py` + `settings.py`             | Keep routes modular   |\n",
    "| Run      | `uvicorn app:app --host 0.0.0.0 --port 8000 --reload` | `--reload` for dev 🔁 |\n",
    "\n",
    "---\n",
    "\n",
    "## 2) 🚧 Build Your First Service\n",
    "\n",
    "### 2.1 🧾 IO Schemas (Pydantic)\n",
    "\n",
    "```python\n",
    "# schemas.py\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ChatIn(BaseModel):\n",
    "    question: str = Field(..., min_length=1)\n",
    "\n",
    "class ChatOut(BaseModel):\n",
    "    answer: str\n",
    "```\n",
    "\n",
    "### 2.2 🔌 Wrap a Runnable with `add_routes`\n",
    "\n",
    "```python\n",
    "# app.py\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from schemas import ChatIn, ChatOut\n",
    "\n",
    "app = FastAPI(title=\"LangServe Demo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer concisely:\\nQ: {question}\\nA:\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = prompt | llm  # Runnable\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/chat\",\n",
    "    input_schema=ChatIn,      # optional: inferred if omitted\n",
    "    output_schema=ChatOut     # optional: use parser for strict JSON\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) 🛣️ Routes & Endpoints\n",
    "\n",
    "| 🔗 Endpoint    | 🧭 Method  | 📦 Body (typical)                                     | 🎁 Returns                 |\n",
    "| -------------- | ---------- | ----------------------------------------------------- | -------------------------- |\n",
    "| `/chat/invoke` | POST       | `{\"input\":{\"question\":\"...\"}, \"config\": {...}}`       | Single result              |\n",
    "| `/chat/batch`  | POST       | `{\"inputs\":[{\"question\":\"...\"}...], \"config\": {...}}` | List of results            |\n",
    "| `/chat/stream` | POST (SSE) | Same as `/invoke`                                     | `text/event-stream` tokens |\n",
    "| Options & CORS | —          | Tags/description/CORS allowlist                       | OpenAPI auto-updates 📜    |\n",
    "\n",
    "> 💡 **Pro tip:** `config` supports `tags`, `metadata`, and `configurable` (e.g. `{\"session_id\":\"abc\"}`) that flow into LCEL/LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) 📡 Streaming (Server & Clients)\n",
    "\n",
    "### 4.1 🧨 SSE from `/stream`\n",
    "\n",
    "* Content-Type: `text/event-stream`\n",
    "* Emits tokens + final message → perfect for chat UIs 💬\n",
    "\n",
    "### 4.2 🐍 Python client streaming\n",
    "\n",
    "```python\n",
    "from langserve import RemoteRunnable\n",
    "rr = RemoteRunnable(\"http://localhost:8000/chat/\")\n",
    "for chunk in rr.stream({\"question\": \"Hello?\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "```\n",
    "\n",
    "### 4.3 🌐 Browser (JS) streaming\n",
    "\n",
    "```js\n",
    "const resp = await fetch(\"http://localhost:8000/chat/stream\", {\n",
    "  method: \"POST\",\n",
    "  headers: { \"Content-Type\": \"application/json\" },\n",
    "  body: JSON.stringify({ input: { question: \"Hi?\" } }),\n",
    "});\n",
    "const reader = resp.body.getReader();\n",
    "const decoder = new TextDecoder();\n",
    "while (true) {\n",
    "  const { value, done } = await reader.read();\n",
    "  if (done) break;\n",
    "  console.log(decoder.decode(value)); // parse SSE frames\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5) 🤝 Clients & RemoteRunnable\n",
    "\n",
    "| 🧰 Client      | 🏃 How to call                                 | 🗒️ Notes                  |\n",
    "| -------------- | ---------------------------------------------- | -------------------------- |\n",
    "| **Python**     | `RemoteRunnable(url).invoke/stream/batch(...)` | Mirrors local Runnable API |\n",
    "| **JavaScript** | `fetch` or generated SDK from OpenAPI          | Prefer SSE for `/stream`   |\n",
    "| **OpenAPI**    | `GET /openapi.json`                            | Generate TS/Java SDKs 🧪   |\n",
    "\n",
    "---\n",
    "\n",
    "## 6) 🔐 Auth & Security\n",
    "\n",
    "| 🚧 Concern    | 🧭 Pattern                                          | 🔎 Snippet          |\n",
    "| ------------- | --------------------------------------------------- | ------------------- |\n",
    "| API key       | FastAPI dependency, read header (e.g., `x-api-key`) | See below           |\n",
    "| CORS          | Allow specific origins                              | Add CORS middleware |\n",
    "| Rate limiting | NGINX/Cloud or middleware                           | Per-IP / per-key    |\n",
    "| Secrets       | Env/vault; never log                                | Pydantic Settings   |\n",
    "\n",
    "**🔑 API-Key example**\n",
    "\n",
    "```python\n",
    "from fastapi import Depends, HTTPException, Header\n",
    "def require_key(x_api_key: str | None = Header(default=None)):\n",
    "    if x_api_key != \"supersecret\":\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n",
    "add_routes(app, chain, path=\"/chat\", dependencies=[Depends(require_key)])\n",
    "```\n",
    "\n",
    "**🌍 CORS**\n",
    "\n",
    "```python\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7) 👀 Observability (LangSmith & OTel)\n",
    "\n",
    "| 📌 Area           | 🛠️ How                                   | 💡 Tip                          |\n",
    "| ----------------- | ----------------------------------------- | ------------------------------- |\n",
    "| LangSmith tracing | `LANGSMITH_API_KEY` + tags/metadata       | tag `env`, `release`, `feature` |\n",
    "| Logs & metrics    | OpenTelemetry for FastAPI/uvicorn         | Merge with infra dashboards     |\n",
    "| Per-route KPIs    | Tag by route/node; watch p50/p95 & tokens | Drive SLOs by path ✅            |\n",
    "\n",
    "---\n",
    "\n",
    "## 8) 🧪 Testing\n",
    "\n",
    "| 🧪 Type         | 🔧 How                                    | 🗒️ Notes                      |\n",
    "| --------------- | ----------------------------------------- | ------------------------------ |\n",
    "| OpenAPI & SDK   | Validate `/openapi.json`; generate TS SDK | Contract tests at boundary     |\n",
    "| Unit & contract | `pytest` + `TestClient(app)`              | Golden outputs & schema checks |\n",
    "| Load tests      | k6/Locust/Gatling vs `/batch` & `/stream` | Watch p95, CPU, memory         |\n",
    "\n",
    "**Contract test**\n",
    "\n",
    "```python\n",
    "from fastapi.testclient import TestClient\n",
    "from app import app\n",
    "\n",
    "def test_invoke_contract():\n",
    "    c = TestClient(app)\n",
    "    r = c.post(\"/chat/invoke\", json={\"input\":{\"question\":\"ping\"}})\n",
    "    assert r.status_code == 200\n",
    "    body = r.json()\n",
    "    assert \"output\" in body and \"answer\" in body[\"output\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9) 🚀 Performance & Scaling\n",
    "\n",
    "| ⚙️ Lever         | 🧭 What to do                                  | 📝 Notes                    |\n",
    "| ---------------- | ---------------------------------------------- | --------------------------- |\n",
    "| Async everywhere | Non-blocking I/O in nodes                      | Offload blocking ops        |\n",
    "| Concurrency      | Uvicorn/Gunicorn workers, thread/process pools | Size by CPU & model latency |\n",
    "| Backpressure     | Queue & drop policies                          | Protect upstream LLMs       |\n",
    "| Timeouts         | Client & server per-route                      | Avoid resource leaks        |\n",
    "| Load balancing   | NGINX/LB, sticky if in-mem state               | Health probes on `/docs` ❤️ |\n",
    "\n",
    "---\n",
    "\n",
    "## 10) 🧠 Caching & State\n",
    "\n",
    "| 🧩 Topic             | 🔧 How                               | 🗒️ Notes                |\n",
    "| -------------------- | ------------------------------------ | ------------------------ |\n",
    "| LLM cache            | LangChain Cache (in-mem/Redis)       | Cache by prompt+params   |\n",
    "| Tool/retriever cache | Memoize deterministic calls          | TTL & invalidation hooks |\n",
    "| Session memory       | Pass `session_id` via `configurable` | Per-user chat state      |\n",
    "| Idempotency          | Request IDs for dedup                | Record in traces         |\n",
    "\n",
    "**Session config (client)**\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"session_id\": \"user-123\"}}\n",
    "RemoteRunnable(\"http://.../chat/\").invoke({\"question\": \"...\"}, config=config)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 11) 🛡️ Error Handling & Reliability\n",
    "\n",
    "| 🚨 Concern           | 🧭 Pattern                                                | 💡 Tip                   |\n",
    "| -------------------- | --------------------------------------------------------- | ------------------------ |\n",
    "| Exceptions → 4xx/5xx | Raise `HTTPException`; map known errors                   | Clear error contracts    |\n",
    "| Retries & backoff    | Client retries idempotent calls; server wraps fragile I/O | Tag retry reason         |\n",
    "| Validation errors    | Pydantic → HTTP 422                                       | Keep schemas strict      |\n",
    "| Circuit breakers     | Fail fast on dependency errors                            | Consider `Retry-After` ⏳ |\n",
    "\n",
    "---\n",
    "\n",
    "## 12) 🌐 Deployment\n",
    "\n",
    "| ☁️ Target            | 🔧 How                                      | 🗒️ Notes           |\n",
    "| -------------------- | ------------------------------------------- | ------------------- |\n",
    "| Containers           | Multi-stage Dockerfile, slim base, non-root | Healthcheck `/docs` |\n",
    "| Cloud run/serverless | Container; set concurrency/timeouts         | Mind cold starts ❄️ |\n",
    "| Reverse proxy & TLS  | NGINX/Traefik + SSL termination             | gzip/br compression |\n",
    "| Env config           | Pydantic Settings + `.env`/vault            | Immutable on boot   |\n",
    "\n",
    "---\n",
    "\n",
    "## 13) 🧩 Advanced\n",
    "\n",
    "| 🪄 Topic               | 🔧 How                                     | 🗒️ Notes                |\n",
    "| ---------------------- | ------------------------------------------ | ------------------------ |\n",
    "| Multimodal I/O         | Pydantic `bytes`/base64/URL fields         | Validate size & MIME     |\n",
    "| Serve LangGraph agents | Wrap `graph_app` via `add_routes`          | Expose `invoke/stream`   |\n",
    "| Tools & files          | `multipart/form-data` → parse to tool args | Handle temp files safely |\n",
    "\n",
    "**Multipart upload (concept)**\n",
    "\n",
    "```python\n",
    "from fastapi import File, UploadFile\n",
    "\n",
    "@app.post(\"/ingest\")\n",
    "async def ingest(file: UploadFile = File(...)):\n",
    "    data = await file.read()\n",
    "    return {\"ok\": True, \"bytes\": len(data)}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14) 🖥️ Frontend Integration\n",
    "\n",
    "| 🎯 Need        | 🧭 Pattern           | 💡 Tip                           |\n",
    "| -------------- | -------------------- | -------------------------------- |\n",
    "| Minimal web UI | `fetch` `/invoke`    | Debounce inputs                  |\n",
    "| Live tokens    | `/stream` (SSE)      | `EventSource` / `ReadableStream` |\n",
    "| CORS           | Allow your FE origin | Lock down in prod 🔒             |\n",
    "\n",
    "**Browser fetch**\n",
    "\n",
    "```js\n",
    "const r = await fetch(\"/chat/invoke\", {\n",
    "  method: \"POST\",\n",
    "  headers: { \"Content-Type\": \"application/json\", \"x-api-key\": \"supersecret\" },\n",
    "  body: JSON.stringify({ input: { question: \"Hello\" } }),\n",
    "});\n",
    "const { output } = await r.json();\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15) ⚡ “Answer-in-a-Minute” Boilerplates\n",
    "\n",
    "**A) Minimal app**\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "app = FastAPI()\n",
    "chain = PromptTemplate.from_template(\"Q:{q}\\nA:\") | ChatOpenAI(temperature=0)\n",
    "add_routes(app, chain, path=\"/qa\")\n",
    "```\n",
    "\n",
    "**B) Protected streaming route**\n",
    "\n",
    "```python\n",
    "from fastapi import Depends, Header, HTTPException\n",
    "def require_key(x_api_key: str | None = Header(default=None)):\n",
    "    if x_api_key != \"k\": raise HTTPException(401, \"bad key\")\n",
    "add_routes(app, chain, path=\"/qa\", dependencies=[Depends(require_key)])\n",
    "# POST /qa/stream with {\"input\":{\"q\":\"...\"}}\n",
    "```\n",
    "\n",
    "**C) Remote client (Python)**\n",
    "\n",
    "```python\n",
    "from langserve import RemoteRunnable\n",
    "rr = RemoteRunnable(\"https://api.example.com/qa/\")\n",
    "ans = rr.invoke({\"q\": \"What is LangServe?\"})\n",
    "```\n",
    "\n",
    "**D) OpenAPI → SDK (concept)**\n",
    "\n",
    "* Download `/openapi.json` → generate TypeScript SDK → call `invoke/batch/stream`.\n",
    "\n",
    "---\n",
    "\n",
    "## 16) ✅ Checklists\n",
    "\n",
    "**Production Readiness**\n",
    "\n",
    "* 🔒 Auth (key) • 🌐 CORS allowlist • ⏱️ Timeouts • 🧯 Retries/backoff\n",
    "* 📈 Tracing/metrics on • 💾 Cache strategy • 🧵 Concurrency sized\n",
    "* 🚦 Health probes • 🧪 Contract tests • 🔁 Rollback plan\n",
    "\n",
    "**Performance**\n",
    "\n",
    "* ⚡ Async everywhere • 🧰 Worker counts tuned • 🧱 Backpressure at ingress\n",
    "* 🧮 Batch where possible • 🧊 Cache hot prompts • 📊 p95 & cost dashboards\n",
    "\n",
    "**Safety**\n",
    "\n",
    "* 🧰 Strict schemas • 📜 Error contracts • 🕵️ PII redaction • 🔐 Secret hygiene\n",
    "\n",
    "---\n",
    "\n",
    "## 17) 🚫 Common Pitfalls → ✅ Fix\n",
    "\n",
    "| ⚠️ Pitfall                    | ✅ Fix                                  |\n",
    "| ----------------------------- | -------------------------------------- |\n",
    "| Free-shape JSON inputs        | Always use Pydantic schemas            |\n",
    "| Blocking calls in async nodes | Offload to thread/process pool         |\n",
    "| No streaming for chat         | Use `/stream` SSE → better TTFB/UX     |\n",
    "| CORS failures in browser      | Configure `allow_origins` correctly    |\n",
    "| Secret leakage in logs        | Redact + disable debug logs in prod    |\n",
    "| Unbounded concurrency         | Set worker limits + queue/backpressure |\n",
    "\n",
    "---\n",
    "\n",
    "## 18) 🎤 Quick Talking Points\n",
    "\n",
    "* *“Any Runnable becomes `/invoke`, `/batch`, `/stream` with strict Pydantic I/O.”*\n",
    "* *“**RemoteRunnable** mirrors local APIs—switch local ↔ remote with a URL.”*\n",
    "* *“Auth + schemas + rate limits at the edge; SSE streaming for buttery UX.”*\n",
    "* *“LangSmith/OTel tracing + caching + contract tests = safe, scalable prod.”*\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
